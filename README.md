# Point and Read ğŸ“–ğŸ”

A deep learning-based text recognition system using **CRNN + BiLSTM + CTC** architecture. Point your camera at any text and let the model read it for you.

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?logo=pytorch&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ—ï¸ Architecture

The recognition pipeline is built on a **CRNN** (Convolutional Recurrent Neural Network) with:

- **CNN Backbone** â€” ResNet-34 (pretrained on ImageNet), modified for single-channel grayscale input
- **Sequence Modelling** â€” 2-layer Bidirectional LSTM (hidden size 256)
- **Output Layer** â€” Fully connected projection with CTC (Connectionist Temporal Classification) decoding

```
Input Image (1Ã—64Ã—W) â†’ ResNet-34 â†’ AdaptivePool â†’ BiLSTM â†’ FC â†’ CTC Decode â†’ Text
```

## ğŸ“‚ Project Structure

```
point-and-read/
â”œâ”€â”€ recognition/          # Core recognition module
â”‚   â”œâ”€â”€ model.py          #   CRNN model definition
â”‚   â”œâ”€â”€ dataset.py        #   Dataset & data loading
â”‚   â”œâ”€â”€ train.py          #   Training loop
â”‚   â”œâ”€â”€ evaluate.py       #   Evaluation metrics (CER, WER)
â”‚   â”œâ”€â”€ inference.py      #   Single-image inference
â”‚   â””â”€â”€ vocab.py          #   Vocabulary / character set
â”œâ”€â”€ preprocessing/        # Image preprocessing & cleaning
â”‚   â””â”€â”€ clean.py          #   Binarization, deskew, noise removal
â”œâ”€â”€ detection/            # Text detection (WIP)
â”‚   â”œâ”€â”€ annotate/         #   Annotation tools
â”‚   â””â”€â”€ train/            #   Detection model training
â”œâ”€â”€ scripts/              # Utility scripts
â”‚   â”œâ”€â”€ verify_iam_structure.py
â”‚   â””â”€â”€ verify_preprocessing.py
â”œâ”€â”€ tests/                # Smoke tests & test fixtures
â”œâ”€â”€ parse_iam.py          # IAM dataset parser
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- CUDA-capable GPU (recommended) or AMD GPU with DirectML

### Installation

```bash
# Clone the repository
git clone https://github.com/AmanSinghNp/point-and-read.git
cd point-and-read

# Create a virtual environment
python -m venv venv
source venv/bin/activate    # Linux/macOS
venv\Scripts\activate       # Windows

# Install dependencies
pip install -r requirements.txt
```

### Dataset Setup

This project uses the [IAM Handwriting Database](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database). The dataset is **not included** in this repository due to its size.

1. Download the IAM dataset and place it in `data/iam/`
2. Run the parser to prepare the data:

```bash
python parse_iam.py
```

3. Verify the dataset structure:

```bash
python scripts/verify_iam_structure.py
```

### Training

```bash
python -m recognition.train
```

### Inference

```bash
python -m recognition.inference --image path/to/image.png
```

### Evaluation

```bash
python -m recognition.evaluate
```

## ğŸ§ª Testing

Run smoke tests to verify the pipeline:

```bash
python -m tests.smoke_test
```

## ğŸ“Š Metrics

| Metric | Description |
|--------|-------------|
| **CER** | Character Error Rate |
| **WER** | Word Error Rate |

## ğŸ—ºï¸ Roadmap

- [x] CRNN + BiLSTM + CTC recognition model
- [x] IAM dataset parsing & preprocessing
- [x] Training pipeline with CTC loss
- [x] Evaluation with CER/WER metrics
- [ ] Text detection module (EAST / CRAFT)
- [ ] End-to-end pipeline: detect â†’ crop â†’ recognise
- [ ] Real-time camera inference
- [ ] Web / mobile demo app

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements

- [IAM Handwriting Database](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database)
- [PyTorch](https://pytorch.org/)
- Inspired by the CRNN paper: *An End-to-End Trainable Neural Network for Image-based Sequence Recognition* (Shi et al., 2015)
